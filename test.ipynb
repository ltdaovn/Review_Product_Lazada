{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ltdaovn/Review_Product_Lazada/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAqPwrn34NXs"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install underthesea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xQrpcXjERDx"
      },
      "source": [
        "import sys\n",
        "import requests\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "SESSION = requests.Session()\n",
        "HEADERS = {\n",
        "    'user-agent': ('Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 '\n",
        "                   '(KHTML, like Gecko) Chrome/48.0.2564.109 Safari/537.36')\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-k1LQBVEeX_"
      },
      "source": [
        "# install selenium\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFCyxEyl4NXz"
      },
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup # parse html\n",
        "import re #regex\n",
        "import csv\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from sklearn.externals import joblib #load, dump pkl\n",
        "from underthesea import word_tokenize #word_tokenize of lines\n",
        "import numpy as np\n",
        "import transformers as ppb # load model BERT\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "# scrap comment = selenium\n",
        "from selenium import webdriver \n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "# import requests"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVTW1qUH4NX1"
      },
      "source": [
        "# Craw comment of product tiki, lazada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64tocg6q4NX4"
      },
      "source": [
        "def load_url_selenium_lazada(url):\n",
        "    # Selenium\n",
        "    #driver = webdriver.Chrome(executable_path='/usr/bin/chromedriver')\n",
        "\n",
        "    driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "    print(\"Loading url=\", url)\n",
        "    driver.get(url)\n",
        "    list_review = []\n",
        "    # just craw 10 page\n",
        "    x=0\n",
        "    while x<10:\n",
        "        try:\n",
        "            #Get the review details here\n",
        "            WebDriverWait(driver,5).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR,\"div.item\")))\n",
        "        except:\n",
        "            print('No has comment')\n",
        "            break\n",
        "        \n",
        "        product_reviews = driver.find_elements_by_css_selector(\"[class='item']\")\n",
        "        # Get product review\n",
        "        for product in product_reviews:\n",
        "            review = product.find_element_by_css_selector(\"[class='content']\").text\n",
        "            if (review != \"\" or review.strip()):\n",
        "                print(review, \"\\n\")\n",
        "                list_review.append(review)\n",
        "        #Check for button next-pagination-item have disable attribute then jump from loop else click on the next button\n",
        "        if len(driver.find_elements_by_css_selector(\"button.next-pagination-item.next[disabled]\"))>0:\n",
        "            break;\n",
        "        else:\n",
        "            button_next=WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"button.next-pagination-item.next\")))\n",
        "            driver.execute_script(\"arguments[0].click();\", button_next)\n",
        "            print(\"next page\")\n",
        "            time.sleep(2)\n",
        "            x +=1\n",
        "    driver.close()\n",
        "    return list_review\n",
        "\n",
        "def load_url_selenium_tiki(url):\n",
        "    #driver=webdriver.Chrome(executable_path='/usr/bin/chromedriver')\n",
        "    driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "    print(\"Loading url=\", url)\n",
        "    driver.get(url)\n",
        "    list_review = []\n",
        "    # just craw 10 page\n",
        "    x=0\n",
        "    while x<10:\n",
        "        try:\n",
        "          \n",
        "            #Get the review details here\n",
        "            WebDriverWait(driver,5).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR,\"div.review-comment\")))\n",
        "        except :\n",
        "            print('Not has comment!')\n",
        "            break\n",
        "        product_reviews = driver.find_elements_by_css_selector(\"[class='review-comment']\")\n",
        "        # Get product review\n",
        "        for product in product_reviews:\n",
        "            review = product.find_element_by_css_selector(\"[class='review-comment__content']\").text\n",
        "            if (review != \"\" or review.strip()):\n",
        "                print(review, \"\\n\")\n",
        "                list_review.append(review)\n",
        "        #Check for button next-pagination-item have disable attribute then jump from loop else click on the next button\n",
        "        try:\n",
        "            #driver.find_element_by_xpath(\"//li[@class='btn next']/a\").click()\n",
        "            button_next=WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"[class = 'btn next']\")))\n",
        "            driver.execute_script(\"arguments[0].click();\", button_next)\n",
        "            print(\"next page\")\n",
        "            time.sleep(2)\n",
        "            x +=1\n",
        "        except (TimeoutException, WebDriverException) as e:\n",
        "            print('Load several page!')\n",
        "            break\n",
        "    driver.close()\n",
        "    return list_review\n",
        "\n",
        "#url = \"https://tiki.vn/dien-thoai-samsung-galaxy-m31-128gb-6gb-hang-chinh-hang-p58259141.html\"\n",
        "#predict(url = 'https://www.lazada.vn/products/iphone-8-plus-chinh-hang-vna-moi-100-chua-kich-hoat-chua-qua-su-dung-bao-hanh-12-thang-tai-ttbh-apple-tra-gop-lai-suat-0-qua-the-tin-dung-man-hinh-retina-hd-55-inch-3d-touch-chip-a11-ios11-i757986604-s1985088475.html')\n",
        "#data = load_url_selenium_tiki(url)\n",
        "\n",
        "\n",
        "url = \"https://www.lazada.vn/products/iphone-12-pro-max-vna-hang-chinh-hang-giao-nhanh-i911378439-s2677122113.html\"\n",
        "data = load_url_selenium_lazada(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MATpXq-I4NX6"
      },
      "source": [
        "# Standard data, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUvAhOM44NX7"
      },
      "source": [
        "\n",
        "def standardize_data(row):\n",
        "    # remove stopword\n",
        "    # Remove . ? , at index final\n",
        "    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
        "    # Remove all . , \" ... in sentences\n",
        "    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
        "        .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
        "        .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
        "        .replace('\"', \" \").replace(\"'\", \" \") \\\n",
        "        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
        "        .replace(\"-\", \" \").replace(\"?\", \" \")\n",
        "\n",
        "    row = row.strip()\n",
        "    return row\n",
        "\n",
        "# Tokenizer\n",
        "def tokenizer(row):\n",
        "    return word_tokenize(row, format=\"text\")\n",
        "\n",
        "def analyze(result):\n",
        "    bad = np.count_nonzero(result)\n",
        "    good = len(result) - bad\n",
        "    print(\"No of bad and neutral comments = \", bad)\n",
        "    print(\"No of good comments = \", good)\n",
        "\n",
        "    if good>bad:\n",
        "        return \"Good! You can buy it!\"\n",
        "    else:\n",
        "        return \"Bad! Please check it carefully!\"\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrH8YILc4NX_"
      },
      "source": [
        "# Processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB72oyDF4NYC"
      },
      "source": [
        "def processing_data(data):\n",
        "    # 1. Standardize data\n",
        "    data_frame = pd.DataFrame(data)\n",
        "    print('data frame:', data_frame)\n",
        "    data_frame[0] = data_frame[0].apply(standardize_data)\n",
        "\n",
        "    # 2. Tokenizer\n",
        "    data_frame[0] = data_frame[0].apply(tokenizer)\n",
        "\n",
        "    # 3. Embedding\n",
        "    X_val = data_frame[0]\n",
        "    return X_val\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BstX1BsG4NYE"
      },
      "source": [
        "# Load Pretrain model BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdllkrS64NYF"
      },
      "source": [
        "def load_pretrainModel(data):\n",
        "    \n",
        "    '''\n",
        "    Load pretrain model/ tokenizers\n",
        "    Return : features\n",
        "    '''\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    #encode lines\n",
        "    tokenized = data.apply((lambda x: tokenizer.encode(x, add_special_tokens = True)))\n",
        "\n",
        "    # get lenght max of tokenized\n",
        "    max_len = 0\n",
        "    for i in tokenized.values:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "    print('max len:', max_len)\n",
        "\n",
        "    # if lenght of tokenized not equal max_len , so padding value 0\n",
        "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "    print('padded:', padded[1])\n",
        "    print('len padded:', padded.shape)\n",
        "\n",
        "    #get attention mask ( 0: not has word, 1: has word)\n",
        "    attention_mask = np.where(padded ==0, 0,1)\n",
        "    print('attention mask:', attention_mask[1])\n",
        "\n",
        "    # Convert input to tensor\n",
        "    padded = torch.tensor(padded)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "\n",
        "    # Load model\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model(padded, attention_mask =attention_mask)\n",
        "    #     print('last hidden states:', last_hidden_states)\n",
        "\n",
        "    features = last_hidden_states[0][:,0,:].numpy()\n",
        "    print('features:', features)\n",
        "    \n",
        "    return features\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTflXtDE4NYG"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdCbmeM94NYG"
      },
      "source": [
        "!wget -c https://github.com/ltdaovn/Review_Product_Lazada/raw/main/save_model.pkl\n",
        "\n",
        "def predict(url):\n",
        "    # 1. Load URL and print comments\n",
        "    if url== \"\":\n",
        "        url = \"https://tiki.vn/dien-thoai-samsung-galaxy-m31-128gb-6gb-hang-chinh-hang-p58259141.html\"\n",
        "    data = load_url_selenium_lazada(url)\n",
        "#     data = load_url_selenium_tiki(url)\n",
        "    data = processing_data(data)\n",
        "    features = load_pretrainModel(data)\n",
        "    # 2. Load weights\n",
        "    model = joblib.load('save_model.pkl')\n",
        "    \n",
        "    # 3. Result\n",
        "    result = model.predict(features)\n",
        "    print(result)\n",
        "    print(analyze(result))\n",
        "# predict(url ='https://tiki.vn/dien-thoai-samsung-galaxy-s20-plus-hang-chinh-hang-p48886153.html?src=search&2hi=0&keyword=s20&src=mega-menu')\n",
        "predict(url = 'https://www.lazada.vn/products/iphone-8-plus-chinh-hang-vna-moi-100-chua-kich-hoat-chua-qua-su-dung-bao-hanh-12-thang-tai-ttbh-apple-tra-gop-lai-suat-0-qua-the-tin-dung-man-hinh-retina-hd-55-inch-3d-touch-chip-a11-ios11-i757986604-s1985088475.html?spm=a2o4n.searchlistcategory.list.4.46d0bdd5OzWEVE&search=1')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}